{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named netCDF4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c263afc16f4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnum2date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate2num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named netCDF4"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import ConfigParser\n",
    "from netCDF4 import num2date, date2num\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'/'.join([grid_dir,[s for s in grids if field[0] in s][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfigSectionMap(section):\n",
    "    dict1 = {}\n",
    "    options = Config.options(section)\n",
    "    for option in options:\n",
    "        try:\n",
    "            dict1[option] = Config.get(section, option)\n",
    "            if dict1[option] == -1:\n",
    "                DebugPrint(\"skip: %s\" % option)\n",
    "        except Exception as e:\n",
    "            print(\"Exception loading %s from .ini !\" % option)\n",
    "            print(e)\n",
    "            dict1[option] = None\n",
    "    return dict1\n",
    "\n",
    "def find_nearest(array,target_values):\n",
    "    idx = np.zeros_like(target_values).astype(int)\n",
    "    for target in range(len(target_values)):\n",
    "        idx[target] = (np.abs(array-target_values[target])).argmin()\n",
    "    return idx\n",
    "\n",
    "def read_grid(var_name,filename,lat_select,lon_select,time_select=None):\n",
    "    #Open netCDF file connection\n",
    "    nc = Dataset(filename, 'r')\n",
    "\n",
    "    #Read in data\n",
    "    lat_ref = nc.variables['latitude'][:]\n",
    "    lon_ref = nc.variables['longitude'][:]\n",
    "    time = nc.variables['time'][:]\n",
    "    data = nc.variables[var_name][:]\n",
    "    #print(np.shape(time))\n",
    "\n",
    "    #Close connection to file\n",
    "    nc.close()\n",
    "     \n",
    "    # If it doesn't exist yet, create the indexes\n",
    "    lat_idx = find_nearest(lat_ref,lat_select)\n",
    "    lon_idx = find_nearest(lon_ref,lon_select)\n",
    "\n",
    "    #Check if we want a single timestamp or multiple\n",
    "    if time_select==None:\n",
    "        data_select=data[:,lat_idx,lon_idx]\n",
    "    else:\n",
    "        data_select=data[time_select,lat_idx,lon_idx]\n",
    "\n",
    "    return data_select, time\n",
    "\n",
    "def grid_to_dict(field,grids_dict,target_loc,ref_time):\n",
    "    fn = '/'.join([grid_dir,[s for s in grids if field[0] in s][0]])\n",
    "    data, datenum = read_grid(field[0],\n",
    "                     fn,\n",
    "                     target_loc[:,1],\n",
    "                     target_loc[:,2],\n",
    "                     )\n",
    "    if np.array_equal(ref_time,datenum):\n",
    "        grids_dict[field[1]] = np.ravel(data)\n",
    "    else:\n",
    "        print(field[1] + ' is shorter than Temperature field. Filling forward...')\n",
    "        infill_time = pd.merge(pd.DataFrame(ref_time),pd.DataFrame(np.column_stack((datenum,datenum))),how='left')\n",
    "        if(pd.isnull(infill_time[1][0])):\n",
    "            infill_time[1][0] = datenum[0]\n",
    "            print('Start times of Temperature and ' + field[1] + \n",
    "                  ' do not match. Filling forward from first row of ' + field[1])\n",
    "        infill_time[1] = infill_time[1].fillna(method='ffill')\n",
    "        infill_time[1] = infill_time[1].astype(np.int64)\n",
    "        \n",
    "        data_out = np.zeros([len(infill_time[1]),np.shape(data)[1]])\n",
    "        for i in range(len(infill_time[1])):\n",
    "            data_out[i,:] = data[np.where(datenum == infill_time[1][i]),:]\n",
    "        grids_dict[field[1]] = np.ravel(data_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DroughtFactor is shorter than Temperature field. Filling forward...\n",
      "Curing is shorter than Temperature field. Filling forward...\n",
      "Start times of Temperature and Curing do not match. Filling forward from first row of Curing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/anaconda3/envs/geopandas/lib/python2.7/site-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CloudCover is shorter than Temperature field. Filling forward...\n",
      "CPU times: user 1min 45s, sys: 3.22 s, total: 1min 49s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "grid_dir = ConfigSectionMap('filepaths')['grid_dir']\n",
    "target_locations_file = ConfigSectionMap('filepaths')['target_locations_file']\n",
    "output_file = ConfigSectionMap('filepaths')['output_file']\n",
    "\n",
    "#field_names is a list of lists: Each list                \n",
    "field_names = ConfigSectionMap('fieldnames')\n",
    "\n",
    "timezone_offset = int(ConfigSectionMap('others')['timezone_offset'])\n",
    "\n",
    "grids = os.listdir(grid_dir)\n",
    "\n",
    "target_locations = np.loadtxt(target_locations_path,delimiter=',')\n",
    "\n",
    "tz_s = timezone_offset*60*60\n",
    "\n",
    "#Search for \"T_SFC\" in grid directory\n",
    "fn = os.sep.join([grid_dir,[s for s in grids if \"T_SFC\" in s][0]])\n",
    "\n",
    "#Read grid of T_SFC, sampling only the required lat/lon's as in Location.txt\n",
    "t_sfc, time_sfc = read_grid('T_SFC',fn,target_locations[:,1],target_locations[:,2])\n",
    "\n",
    "#Convert timestamps from the netCDF to strings via python datetime objects\n",
    "timestamps_formatted = [num2date(ts+tz_s,'seconds since 1970-01-01 00:00:00').strftime(\"%Y-%d-%m %H:%M\") for ts in time_sfc]\n",
    "\n",
    "#Create an empty array of strings of the same size of the sampled T_SFC, where each cell is the right number of characters for the string timestamps\n",
    "times_out = np.chararray(np.shape(t_sfc),itemsize=len(timestamps_formatted[0]))\n",
    "geo_id = np.zeros(np.shape(t_sfc))\n",
    "\n",
    "\n",
    "\n",
    "#Loop through Location.txt geo_id's provided \n",
    "for i in range(len(t_sfc[:,0])):\n",
    "    #Fill in geo_ids\n",
    "    geo_id[i,:] = target_locations[:,0].astype(int)\n",
    "    \n",
    "for i in range(len(t_sfc[0,:])):\n",
    "    #Fill in timestamps \n",
    "    times_out[:,i] = timestamps_formatted # timestamps\n",
    "\n",
    "grids_out_dictionary = {} \n",
    "\n",
    "grids_out_dictionary['Location'] = np.ravel(geo_id).astype(int)\n",
    "grids_out_dictionary['Date'] = np.ravel(times_out)\n",
    "grids_out_dictionary['Temperature'] = np.ravel(t_sfc)\n",
    "\n",
    "for field, outname in field_names.iteritems():\n",
    "    grid_to_dict([field,outname],grids_out_dictionary,target_locations,time_sfc)\n",
    "    \n",
    "df = pd.DataFrame(data=grids_out_dictionary)\n",
    "\n",
    "#Convert Windspeed from kts to km/hr\n",
    "df['WindSpeed'] = df['WindSpeed']*1.852 \n",
    "\n",
    "df = df[['Location','Date','Temperature','RH','WindDir','WindSpeed','DroughtFactor','Curing','CloudCover']]\n",
    "df = df.sort_values(by=['Location','Date'])\n",
    "\n",
    "print('Saving output to')\n",
    "df.to_csv(output_file,float_format='%.1f',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import ConfigParser\n",
    "from netCDF4 import num2date, date2num\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'fieldnames': {u'Curing_SFC': u'Curing',\n",
       "  u'DF_SFC': u'DroughtFactor',\n",
       "  u'RH_SFC': u'RH',\n",
       "  u'Sky_SFC': u'CloudCover',\n",
       "  u'Wind_Dir_SFC': u'WindDir',\n",
       "  u'Wind_Mag_SFC': u'WindSpeed'},\n",
       " u'filepaths': {u'grid_dir': u'./files_in/20141114_0921',\n",
       "  u'output_file': u'./grids_out.csv',\n",
       "  u'target_locations_file': u'./files_in/BOM_Grids_Points.txt'},\n",
       " u'timezone_offset': 10}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#json_data=open(process_grids_config.json).read()\n",
    "\n",
    "data = json.load(open('../process_grids_config.json'))\n",
    "\n",
    "#data = json.loads(json_data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./files_in/20141114_0921\n",
      "./files_in/BOM_Grids_Points.txt\n",
      "./grids_out.csv\n"
     ]
    }
   ],
   "source": [
    "    # Load config\n",
    "    config = json.load(open('../process_grids_config.json'))\n",
    "\n",
    "    grid_dir = config['filepaths']['grid_dir']\n",
    "    target_locations_file = config['filepaths']['target_locations_file']\n",
    "    output_file = config['filepaths']['output_file']\n",
    "    \n",
    "    print(grid_dir)\n",
    "    print(target_locations_file)\n",
    "    print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_location = './process_grids_config_NB_testing.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,target_values):\n",
    "    idx = np.zeros_like(target_values).astype(int)\n",
    "    for target in range(len(target_values)):\n",
    "        idx[target] = (np.abs(array-target_values[target])).argmin()\n",
    "    return idx\n",
    "\n",
    "def read_grid(var_name,filename,lat_select,lon_select,time_select=None):\n",
    "    #Open netCDF file connection\n",
    "    nc = Dataset(filename, 'r')\n",
    "\n",
    "    #Read in data\n",
    "    lat_ref = nc.variables['latitude'][:]\n",
    "    lon_ref = nc.variables['longitude'][:]\n",
    "    time = nc.variables['time'][:]\n",
    "    data = nc.variables[var_name][:]\n",
    "    #print(np.shape(time))\n",
    "\n",
    "    #Close connection to file\n",
    "    nc.close()\n",
    "\n",
    "    # If it doesn't exist yet, create the indexes\n",
    "    lat_idx = find_nearest(lat_ref,lat_select)\n",
    "    lon_idx = find_nearest(lon_ref,lon_select)\n",
    "\n",
    "    #Check if we want a single timestamp or multiple\n",
    "    if time_select==None:\n",
    "        data_select=data[:,lat_idx,lon_idx]\n",
    "    else:\n",
    "        data_select=data[time_select,lat_idx,lon_idx]\n",
    "\n",
    "    return data_select, time\n",
    "\n",
    "def grid_to_dict(field,grids_dict,target_loc,ref_time):\n",
    "    try:\n",
    "        fn = '/'.join([grid_dir,[s for s in grids if field[0] in s][0]])\n",
    "    except:\n",
    "        print('Error loading %s, check files exist and are correct in config json'  % field[0])\n",
    "    data, datenum = read_grid(field[0],\n",
    "                     fn,\n",
    "                     target_loc[:,1],\n",
    "                     target_loc[:,2],\n",
    "                     )\n",
    "    if np.array_equal(ref_time,datenum):\n",
    "        print('Retrieving ' + field[1] + ' from grids.')\n",
    "        grids_dict[field[1]] = np.ravel(data)\n",
    "    else:\n",
    "        print('Retrieving ' + field[1] + ' from grids.')\n",
    "        print(field[1] + ' is shorter than Temperature field. Filling forward...')\n",
    "        infill_time = pd.merge(pd.DataFrame(ref_time),pd.DataFrame(np.column_stack((datenum,datenum))),how='left').copy()\n",
    "        if(pd.isnull(infill_time[1][0])):\n",
    "            infill_time[1][0] = datenum[0]\n",
    "            print('Start times of Temperature and ' + field[1] +\n",
    "                  ' do not match. Filling forward from first row of ' + field[1])\n",
    "        infill_time[1] = infill_time[1].fillna(method='ffill')\n",
    "        infill_time[1] = infill_time[1].astype(np.int64)\n",
    "\n",
    "        data_out = np.zeros([len(infill_time[1]),np.shape(data)[1]])\n",
    "        for i in range(len(infill_time[1])):\n",
    "            data_out[i,:] = data[np.where(datenum == infill_time[1][i]),:]\n",
    "        grids_dict[field[1]] = np.ravel(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving DroughtFactor from grids.\n",
      "DroughtFactor is shorter than Temperature field. Filling forward...\n",
      "Retrieving WindSpeed from grids.\n",
      "Retrieving WindDir from grids.\n",
      "Retrieving RH from grids.\n",
      "Retrieving Curing from grids.\n",
      "Curing is shorter than Temperature field. Filling forward...\n",
      "Start times of Temperature and Curing do not match. Filling forward from first row of Curing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nick/anaconda3/envs/geopandas/lib/python2.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving CloudCover from grids.\n",
      "CloudCover is shorter than Temperature field. Filling forward...\n",
      "Saving output to ../grids_out.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load config\n",
    "    config = json.load(open(config_file_location))\n",
    "\n",
    "    grid_dir = config['filepaths']['grid_dir']\n",
    "    target_locations_file = config['filepaths']['target_locations_file']\n",
    "    output_file = config['filepaths']['output_file']\n",
    "\n",
    "    #field_names is a list of lists: Each list\n",
    "    field_names = config['fieldnames']\n",
    "\n",
    "    timezone_offset = int(config['timezone_offset'])\n",
    "\n",
    "    grids = os.listdir(grid_dir)\n",
    "\n",
    "    target_locations = np.loadtxt(target_locations_file,delimiter=',')\n",
    "\n",
    "    tz_s = timezone_offset*60*60\n",
    "\n",
    "    #Search for \"T_SFC\" in grid directory\n",
    "    try:\n",
    "        fn = os.sep.join([grid_dir,[s for s in grids if \"T_SFC\" in s][0]])\n",
    "    except Exception as e:\n",
    "        print(\"Temperature by the name T_SFC not found in grids! Error:\")\n",
    "        print(e)\n",
    "        print(\"Files pointed to include:\")\n",
    "        print(grids)\n",
    "\n",
    "    #Read grid of T_SFC, sampling only the required lat/lon's as in Location.txt\n",
    "    print('Retrieving Temperature from grids.')\n",
    "    t_sfc, time_sfc = read_grid('T_SFC',fn,target_locations[:,1],target_locations[:,2])\n",
    "\n",
    "    #Convert timestamps from the netCDF to strings via python datetime objects\n",
    "    timestamps_formatted = [num2date(ts+tz_s,'seconds since 1970-01-01 00:00:00').strftime(\"%Y-%d-%m %H:%M\") for ts in time_sfc]\n",
    "\n",
    "    #Create an empty array of strings of the same size of the sampled T_SFC, where each cell is the right number of characters for the string timestamps\n",
    "    times_out = np.chararray(np.shape(t_sfc),itemsize=len(timestamps_formatted[0]))\n",
    "    geo_id = np.zeros(np.shape(t_sfc))\n",
    "\n",
    "\n",
    "\n",
    "    #Loop through Location.txt geo_id's provided\n",
    "    for i in range(len(t_sfc[:,0])):\n",
    "        #Fill in geo_ids\n",
    "        geo_id[i,:] = target_locations[:,0].astype(int)\n",
    "\n",
    "    for i in range(len(t_sfc[0,:])):\n",
    "        #Fill in timestamps\n",
    "        times_out[:,i] = timestamps_formatted # timestamps\n",
    "\n",
    "    grids_out_dictionary = {}\n",
    "\n",
    "    grids_out_dictionary['Location'] = np.ravel(geo_id).astype(int)\n",
    "    grids_out_dictionary['Date'] = np.ravel(times_out)\n",
    "    grids_out_dictionary['Temperature'] = np.ravel(t_sfc)\n",
    "\n",
    "    for field, outname in field_names.iteritems():\n",
    "        names = [field,outname]\n",
    "        grid_to_dict(names,grids_out_dictionary,target_locations,time_sfc)\n",
    "\n",
    "    df = pd.DataFrame(data=grids_out_dictionary)\n",
    "\n",
    "    #Convert Windspeed from kts to km/hr\n",
    "    df['WindSpeed'] = df['WindSpeed']*1.852\n",
    "\n",
    "    df = df[['Location','Date','Temperature','RH','WindDir','WindSpeed','DroughtFactor','Curing','CloudCover']]\n",
    "    df = df.sort_values(by=['Location','Date'])\n",
    "\n",
    "    print('Saving output to ' + output_file)\n",
    "    df.to_csv(output_file,float_format='%.1f',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
